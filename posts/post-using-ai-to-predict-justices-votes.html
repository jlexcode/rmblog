
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Using AI to Predict Justices' Votes - Reasonable Machines</title>
    <meta name="description" content="It is notoriously difficult to predict Supreme Court votes. The leading algorithmic approaches produce vote-level predictions with about 70 percent accuracy. Wisdom of human crowds tends to be higher—about 80...">
    <meta name="keywords" content="law, AI, organizations, legal technology, social science, research">
    <meta name="author" content="Jed Stiglitz">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://reasonablemachines.io/post-using-ai-to-predict-justices-votes.html">
    <meta property="og:title" content="Using AI to Predict Justices' Votes - Reasonable Machines">
    <meta property="og:description" content="It is notoriously difficult to predict Supreme Court votes. The leading algorithmic approaches produce vote-level predictions with about 70 percent accuracy. Wisdom of human crowds tends to be higher—about 80...">
    <meta property="og:site_name" content="Reasonable Machines">
    
    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://reasonablemachines.io/post-using-ai-to-predict-justices-votes.html">
    <meta property="twitter:title" content="Using AI to Predict Justices' Votes - Reasonable Machines">
    <meta property="twitter:description" content="It is notoriously difficult to predict Supreme Court votes. The leading algorithmic approaches produce vote-level predictions with about 70 percent accuracy. Wisdom of human crowds tends to be higher—about 80...">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://reasonablemachines.io/post-using-ai-to-predict-justices-votes.html">
    
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/@supabase/supabase-js@2"></script>
    <link href="https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&family=Inter:wght@400;500&display=swap" rel="stylesheet">
    <link href="styles.css" rel="stylesheet">
    <style>
        .post-link {
            color: #3b82f6; /* same blue as about page */
        }
    </style>
</head>
<body class="bg-white text-black font-sans">
    <div class="max-w-2xl mx-auto px-4 py-8">
        <div id="header"></div>
        
        <!-- Breadcrumbs -->
        <nav class="mb-6 text-sm">
            <a href="../index.html" class="text-black font-['Space_Mono'] hover:underline">← Back to Home</a>
        </nav>

        <!-- Post content -->
        <div id="post-content">
            <header class="mb-8">
                <h1 class="text-3xl font-normal text-black mb-3 font-['Space_Mono']">Using AI to Predict Justices' Votes</h1>
                <div class="text-black mb-6 font-['Space_Mono']">September 11, 2025 • jed</div>
            </header>
            
            <article class="prose prose-lg max-w-none">
                <div class="text-black leading-relaxed font-['Inter']">It is notoriously difficult to predict Supreme Court votes. The leading <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0174698&trk=public_post_comment-text" target="_blank" rel="noopener noreferrer" class="post-link">algorithmic approaches</a> produce vote-level predictions with about 70 percent accuracy. Wisdom of <a href="https://fantasyscotus.net/case/list/" target="_blank" rel="noopener noreferrer" class="post-link">human crowds</a> tends to be higher—about 80 percent accuracy. Case-level predictions tend to be lower. For example, last term (OT2024) the human crowds predicted vote outcomes with an accuracy of 80.6 percent, but case-level outcomes with an accuracy of 76.3 percent. Both the algorithmic and human results include near-decision information, such as oral argument data, amicus briefs, etc.<br><br>This is a difficult task for a few reasons. First, law is very high-dimensional and it is challenging to capture the features relevant to decisions without also capturing features that introduce noise and degrade model performance. Here, I use “model” permissively, including human models of justice decision-making. Second, as the Court is at the top of the judicial hierarchy, the cases that it hears tend to the most complex, often pitting one valid signal against other valid signals (e.g., a conflict between precedents or legal provisions). The resolution of those clashing signals is the Court’s job, and it will typically be unclear a priori what the resolution will be. Prominent theories of litigation, indeed, predict that we only observe uncertain cases—if they were certain, parties would save resources and settle. Third, the Court and composition of cases changes over time, and it can be difficult to capture that temporal drift. <br><br>Despite these challenges, I wanted to see what kind of performance would be produced by newer models adapted to the legal domain. I experimented with a variety of models and approaches, but for now landed on using signals from the party filings, oral argument, and amicus briefs, and trained adapters on Llama 70b models for the task of predicting votes. I produced the feature set from those raw inputs and aimed to maximize the signal/noise ratio. The resulting justice bots will take information from a new case and predict how a given justice will vote on it.<br><br>I trained on terms since Justice Kagan took her seat but stopped in OT2023. This allows us to evaluate model performance against OT2024, the term that wrapped up in June 2025. In this context, information can leak across cases within terms, and it is important to validate against data that is temporally cordoned from the training data rather than use standard cross validation. <br><br>How did the models do? Well, first, let me acknowledge again that this is a difficult problem. Even with modern language models, it is easy to underperform relative to SOTA. <br><br>But after pushing theoretically relevant features and carefully attending to best training practices, the model matched algorithmic SOTA at vote level accuracy (71 percent). More impressive, it bested the humans at case-level accuracy (79 percent). <br><br>It is common to assess performance using the F1 score, along with recall and precision. Recall is the proportion of positive instances correctly identified; and precision tells us the proportion of cases the model marks as true are in fact true. Together, they give a measure of false positives and negatives, and the F1 score is the (harmonic) average of the two. Overall, at the vote level, F1 score is 0.71 when weighted by class frequency and 0.67 when unweighted by frequency. The affirm class is more difficult to predict and that shows up in the table through a lower F1 score.<br><br><br><div class="overflow-x-auto my-2"><table class="w-full border-collapse border border-gray-300"><thead><tr class="bg-gray-100"><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Class</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Precision</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Recall</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">F1</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Support</th></tr></thead><tbody><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Affirm</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.6</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.49</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.54</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">173</td></tr><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Reverse</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.76</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.83</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.79</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">328</td></tr><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Macro (weighted)</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.71</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td></tr><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Macro (unweighted)</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.67</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td></tr></tbody></table><p class="text-sm text-gray-600 mt-1 text-center font-['Inter'] italic">Vote-level performance</p></div><br><br>Also important, the model calibration appears reasonable. Calibration refers to the model’s ability to tell us how confident it is in its predictions. So if it says there is a fifty percent chance of an event, does the observed event happen fifty percent of the time? Figure 1 bins the predicted probabilities from the model for reversal and shows how often, within each bin, the vote turns out to be reversal. A perfectly calibrated model would have points for each bin exactly on the 45-degree angle line. The observed calibration is roughly along that line. The expected calibration error (ECE), or departure from the line of perfect correspondence, is 0.04—the average bin is about four percentage points off target. We can also look at the Brier score, which is the mean square of the difference of the label and the predicted probability. Lower is better. The model’s Brier score is 0.19. That can be used later to compare to other models.<br><br><figure class="my-2"><img src="https://xlglobsjkfpfpkxlivki.supabase.co/storage/v1/object/public/blog-images/1757617799175-76lgy0.png" alt="Vote-level calibration" class="w-full rounded-lg shadow-sm"><figcaption class="text-sm text-gray-600 mt-1 text-center font-['Inter']">Vote-level calibration</figcaption></figure><br><br>Unlike other models, including human models, this model appears better at the case level than the vote-level. I plan to post more on that later. But for now consider table 2, which reports model performance by class at the case level. All relevant measures are stronger at the case level than the vote level. On calibration, the ECE is somewhat worse (0.10) but the Brier score is somewhat stronger (0.17). <br><br><br><div class="overflow-x-auto my-2"><table class="w-full border-collapse border border-gray-300"><thead><tr class="bg-gray-100"><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Class</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Precision</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Recall</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">F1</th><th class="border border-gray-300 px-3 py-2 text-left font-['Space_Mono'] font-medium">Support</th></tr></thead><tbody><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Affirm</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.64</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.47</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.54</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">15</td></tr><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Reverse</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.82</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.9</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.86</td><td class="border border-gray-300 px-3 py-2 font-['Inter']">41</td></tr><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Macro (weighted)</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.77</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td></tr><tr class="hover:bg-gray-50"><td class="border border-gray-300 px-3 py-2 font-['Inter']">Macro (unweighted)</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td><td class="border border-gray-300 px-3 py-2 font-['Inter']">0.7</td><td class="border border-gray-300 px-3 py-2 font-['Inter']"></td></tr></tbody></table><p class="text-sm text-gray-600 mt-1 text-center font-['Inter'] italic">Case-level performance</p></div><br><br>I plan to investigate a variety of models in the coming posts. What happens if we drop oral arguments? Amicus data? What does the model predict for the current term?<br><br>Until soon.</div>
            </article>
        </div>
    </div>

    <script src="../header.js"></script>
    
    <!-- PostHog Analytics -->
    <script>
        !function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]);t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.async=!0,p.src=s.api_host+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset isFeatureEnabled onFeatureFlags getFeatureFlag getFeatureFlagPayload reloadFeatureFlags group updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures getActiveMatchingSurveys getSurveys".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
        posthog.init('phc_wfVnnyCEXjwV0azeFP8TlojFUL83RJ3j9WWlSxMV9VQ', {api_host: 'https://app.posthog.com'})
        
        // Track post view
        posthog.capture('post_viewed', {
            post_title: 'Using AI to Predict Justices' Votes',
            post_slug: 'using-ai-to-predict-justices-votes',
            post_id: '9',
            post_featured: false,
            post_date: '2025-09-11T19:16:22.103+00:00'
        })
    </script>
</body>
</html>